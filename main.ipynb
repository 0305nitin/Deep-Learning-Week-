{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the libraries\n",
    "import json\n",
    "import pygame as pg\n",
    "import sys\n",
    "import threading\n",
    "import numpy as np\n",
    "import rect\n",
    "import copy\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # For reproducible results\n",
    "\n",
    "\n",
    "# Variables for simulation window\n",
    "# Variables for the width and height of the simulation window\n",
    "WIDTH = 1100\n",
    "HEIGHT = 700\n",
    "\n",
    "# Variable for the width and the height of the simulation inside the main window\n",
    "# Must be <= HEIGHT and WIDTH\n",
    "GRID_WIDTH = WIDTH - 400\n",
    "GRID_HEIGHT = HEIGHT\n",
    "FPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for storing the Qvlaues for each grid cell\n",
    "class GridCell:\n",
    "    def __init__(self):\n",
    "        self.qvals = [0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to create the ocean environment for the simulation\n",
    "\n",
    "class OceanEnvironment:\n",
    "    def __init__(self, row, col, no_row, no_col, mode):\n",
    "        self.current_row = row\n",
    "        self.current_col = col\n",
    "\n",
    "        self.max_rows = no_row - 1\n",
    "        self.max_cols = no_col - 1\n",
    "\n",
    "        self.color = 0\n",
    "\n",
    "        if mode == 0:\n",
    "            self.fish_population = self.gradient_fish_generator()\n",
    "        else:\n",
    "            self.fish_population = self.random_fish_generator()\n",
    "        self.environment_val = 0\n",
    "\n",
    "        self.population_history = []\n",
    "\n",
    "    def gradient_fish_generator(self):\n",
    "        dist_from_shore_y = abs(self.max_rows - self.current_row)\n",
    "        dist_from_shore_x = abs(self.max_cols - self.current_col)\n",
    "\n",
    "        diag_dist = pow(pow(dist_from_shore_x, 2) + pow(dist_from_shore_y, 2), 0.5)\n",
    "        max_dist = pow(pow(self.max_rows, 2) + pow(self.max_cols, 2), 0.5)\n",
    "        fish_pop = int((255 / max_dist) * diag_dist)\n",
    "        if fish_pop == 0:\n",
    "            return 1\n",
    "        return fish_pop\n",
    "\n",
    "\n",
    "    def random_fish_generator(self):\n",
    "        return np.random.randint(5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to create and handle the actor for Qlearning\n",
    "class Boat:\n",
    "    def __init__(self, grid):\n",
    "        # position is the grid coordinates of the boat\n",
    "        self.reset_pos = (len(grid) // 2, len(grid) - 1)\n",
    "\n",
    "        self.pos = list(self.reset_pos)\n",
    "\n",
    "        self.fuel_used = 0\n",
    "        self.grid = grid\n",
    "\n",
    "    def move_up(self):\n",
    "        if self.pos[1] > 0:\n",
    "            self.pos[1] -= 1\n",
    "            self.render()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def move_down(self):\n",
    "        if self.pos[1] < len(self.grid) - 1:\n",
    "            self.pos[1] += 1\n",
    "            self.render()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def move_left(self):\n",
    "        if self.pos[0] > 0:\n",
    "            self.pos[0] -= 1\n",
    "            self.render()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def move_right(self):\n",
    "        if self.pos[0] < len(self.grid) - 1:\n",
    "            self.pos[0] += 1\n",
    "            self.render()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def fish(self):\n",
    "        decline = 10\n",
    "        self.grid[self.pos[0]][self.pos[1]].fish_population -= decline\n",
    "\n",
    "    def render(self):\n",
    "        cell_width = GRID_WIDTH / len(self.grid[0])\n",
    "        cell_height = GRID_HEIGHT / len(self.grid)\n",
    "        rect = (cell_width * self.pos[0], cell_height * self.pos[1], cell_width, cell_height)\n",
    "        pg.draw.rect(screen, white, rect)\n",
    "        pg.display.update(pg.Rect(rect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Q-learning Algorithm\n",
    "\n",
    "Action Space\n",
    "\n",
    "0 -> move up<br>\n",
    "1 -> move down<br>\n",
    "2 -> move left<br>\n",
    "3 -> move right<br>\n",
    "4 -> fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Epsilon greedy policy for choosing the action for Q-learning\n",
    "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
    "    random_int = random.uniform(0, 1)\n",
    "    if random_int > epsilon:\n",
    "        action = Qtable[state[0]][state[1]].qvals.index(max(Qtable[state[0]][state[1]].qvals))\n",
    "    else:\n",
    "        action = random.randint(0, 4)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to return the rewards for each action taken\n",
    "\n",
    "def take_step(boat, action, environment_grid, avg_population):\n",
    "    population_d = 70\n",
    "    if action == 0:\n",
    "        if boat.move_up():\n",
    "            return -2\n",
    "        return -100\n",
    "    elif action == 1:\n",
    "        if boat.move_down():\n",
    "            return -1.5\n",
    "        return -100\n",
    "    elif action == 2:\n",
    "        if boat.move_left():\n",
    "            return -1\n",
    "        return -100\n",
    "    elif action == 3:\n",
    "        if boat.move_right():\n",
    "            return -1\n",
    "        return -100\n",
    "    elif action == 4:\n",
    "        fish_population = environment_grid[boat.pos[1]][boat.pos[0]].fish_population\n",
    "        if fish_population < avg_population:\n",
    "            return -1*fish_population/(population_d*255)\n",
    "        return (fish_population/population_d)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual Q learninng algorithm\n",
    "\n",
    "learning_rate = 0.5\n",
    "gamma = 0.95\n",
    "\n",
    "\n",
    "def train(training_episodes, decay_rate, max_steps, Qtable, environment_grid, boat, avg_population):\n",
    "\n",
    "    max_epsilon = 1.0\n",
    "    min_epsilon = 0.05\n",
    "\n",
    "    for episode in range(training_episodes):\n",
    "\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate * episode)\n",
    "        # Reset the environment\n",
    "        state = list(boat.reset_pos)\n",
    "        copy_env_grid = copy.deepcopy(list(environment_grid))\n",
    "        boat.pos = state\n",
    "\n",
    "        # repeat\n",
    "        for step in range(max_steps):\n",
    "\n",
    "            action = epsilon_greedy_policy(Qtable, state, epsilon)\n",
    "            reward = take_step(boat, action, copy_env_grid, avg_population)\n",
    "            new_state = boat.pos\n",
    "\n",
    "            state_val = Qtable[state[1]][state[0]].qvals\n",
    "            Qtable[state[1]][state[0]].qvals[action] = state_val[action] + learning_rate * (\n",
    "                        reward + gamma * max(Qtable[new_state[1]][new_state[0]].qvals) - state_val[action])\n",
    "\n",
    "            if action == 4:\n",
    "                copy_env_grid[state[1]][state[0]].fish_population -= 100\n",
    "\n",
    "            # Our state is the new state\n",
    "            state = new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generating the Q-table\n",
    "def create_qtable(rows, columns):\n",
    "    return [[GridCell() for j in range(columns)] for i in range(rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generatig the environment grid\n",
    "def create_env(rows, columns, mode):\n",
    "    return [[OceanEnvironment(i, j, rows, columns, mode) for j in range(columns)] for i in range(rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
